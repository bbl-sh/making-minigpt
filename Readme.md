# GPT Implementation from Scratch

This repository contains my implementation of GPT from scratch using PyTorch, inspired by **llm from scratch** book from sebastian Resbescka (The best book for learning about llm and its implementation) also from Andrej Karpathy's series on building GPT.

## Objectives

* Understand the fundamental components of GPT.
* Implement each module step-by-step using PyTorch.
* Develop a working GPT model capable of basic text generation.

## Progress

* [x] Data processing and tokenization
* [x] Transformer architecture implementation
* [x] Implementation of GPT block
* [x] Text generation using GPT block
* [x] Pretraining
* [x] Testing and text generation
* [ ] Training loop and optimization
* [ ] Classification using models
* [ ] Fine-tuning using opensource-llms

---

### References

* This all implementation is based on the **llm from scratch** book from sebastian Resbescka (The best book for learning llm, and implementing it). I would highly recommend if you want to learn about llms and implenting it.
* Also inspired from [Andrej Karpathy - GPT from Scratch Series](https://www.youtube.com/playlist?list=PLyqSpQzTE6M9gCgGiBFPs3Svr0_yO4S4u)
