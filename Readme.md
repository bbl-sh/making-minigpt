# GPT Implementation from Scratch

This repository contains my implementation of GPT from scratch using PyTorch, inspired by Andrej Karpathy's series on building GPT.

## Objectives

* Understand the fundamental components of GPT.
* Implement each module step-by-step using PyTorch.
* Develop a working GPT model capable of basic text generation.

## Progress

* [*] Data processing and tokenization
* [*] Transformer architecture implementation
* [ ] Training loop and optimization
* [ ] Testing and text generation
* [ ] Classification using models
* [ ] Fine-tuning using opensource-llms

---

### References

* This all implementation is based on the **llm from scratch** book from sebastian Resbescka (The best book for learning llm, and implementing it). I would highly recommend if you want to learn about llms and implenting it.
* Also inspired from [Andrej Karpathy - GPT from Scratch Series](https://www.youtube.com/playlist?list=PLyqSpQzTE6M9gCgGiBFPs3Svr0_yO4S4u)
